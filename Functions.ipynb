{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all packages needed \n",
    "#1) Fundatmental \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#2) Preprocessing \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "#3) Model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#4) Validation  \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "#5) Performance metrics  \n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score,roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(scaler,train,test):\n",
    "    #if no scaler is specified the data is untouched\n",
    "    if scaler is None:\n",
    "        train,test=train,test\n",
    "    #if the scaler is MinMaxScaler then the MinMaxScaler is applied to the data\n",
    "    elif scaler==MinMaxScaler:\n",
    "        #Calling the scaler\n",
    "        scaler=preprocessing.MinMaxScaler()\n",
    "        #Fitting it to the training data\n",
    "        train=scaler.fit_transform(train)\n",
    "        #Transforming the test data based on the scaling computed from the training data\n",
    "        test=scaler.transform(test)\n",
    "    return train,test\n",
    "\n",
    "def impute_data(imputer,train,test):\n",
    "    if imputer is None:\n",
    "        train,test=train,test\n",
    "    elif imputer==KNNImputer:\n",
    "        imputer_1 = KNNImputer(n_neighbors=5)\n",
    "        train=imputer_1.fit_transform(train)\n",
    "        test = imputer_1.transform(test)\n",
    "    elif imputer==SimpleImputer:\n",
    "        imputer_1 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        train=imputer_1.fit_transform(train)\n",
    "        test = imputer_1.transform(test)\n",
    "    return train,test\n",
    "    \n",
    "def smote_data(smote_type,cat_indx,X_train, y_train):\n",
    "    if smote_type is None:\n",
    "        X_train, y_train=X_train, y_train \n",
    "    elif smote_type==SMOTE:\n",
    "        oversample = SMOTE(random_state=9)\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)    \n",
    "    elif smote_type==SMOTENC:\n",
    "        oversample = SMOTENC(categorical_features= cat_indx, random_state=0)\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)    \n",
    "    return X_train,y_train\n",
    "\n",
    "def data_prep(data_model):\n",
    "    factor = pd.factorize(data_model['biodiag'])\n",
    "    data_model.biodiag = factor[0]\n",
    "    y = np.array(data_model.loc[:, data_model.columns == \"biodiag\"])\n",
    "    X = data_model.loc[:, data_model.columns != \"biodiag\"]\n",
    "    coulmnNames=list(X.columns)\n",
    "    X=np.array(X)\n",
    "    return X,y,coulmnNames\n",
    "\n",
    "def sentivity_specificity(y_true,y_pred):\n",
    "    #Compute the four components of the cofucion matrix: true negative, false positive, false negative, true positive.\n",
    "    tn, fp, fn, tp  = confusion_matrix(y_true, y_pred).ravel()\n",
    "    #Compute the sensitivity,a measure of how well a test can identify true positives. \n",
    "    sensitivity=tp/(tp+fn)\n",
    "    #Compute the specificity, a measure of how well a test can identify true negatives.\n",
    "    specificity=tn/(tn + fp)\n",
    "    return sensitivity,specificity\n",
    "\n",
    "\n",
    "def print_importance(featureImportance,coulmnNames):\n",
    "    importance=pd.DataFrame(featureImportance, columns = ['importance'])\n",
    "    importance[\"feature\"]=coulmnNames\n",
    "    importance=importance[[\"feature\",\"importance\"]]\n",
    "    print(importance.sort_values(by=['importance'],ascending=False))\n",
    "    \n",
    "\n",
    "def featureimportance(X,y,model,scaler,imputer):\n",
    "    #define the split mechanism as leave one out for evaluation \n",
    "    cv = LeaveOneOut()\n",
    "    model=model\n",
    "    #Create three lists to store the true y values (real and predicted) and the importance values for each iteration of leave one out validation\n",
    "    y_true, y_pred, importancelist = list(), list(), list()\n",
    "    #Run the leave one out \n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # split data, using just one sample as the test \n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        #Scale the data if called in the definition, where \"None\" means no scaling is applied\n",
    "        X_train,X_test=scale_data(scaler,X_train,X_test)\n",
    "        #Impute missing values using the technique indicated where \"knn\" is k-nearest neighbor and \"mean\" is the mean.\n",
    "        X_train,X_test=impute_data(imputer,X_train,X_test)\n",
    "        #Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        #Evaluate the model\n",
    "        yhat = model.predict(X_test)\n",
    "        #Store the predicted and true values of \"y\"\n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(yhat[0])\n",
    "        #Compute the feature importance \n",
    "        importance = model.feature_importances_\n",
    "        #Store the feature importance \n",
    "        importancelist.append(importance)\n",
    "        \n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    fpr,tpr,threshold=roc_curve(y_true,y_pred,pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #Compute importance as the mean of all leave one out importance scores\n",
    "    importance=np.mean(importancelist, axis=0)\n",
    "    #Compute the four components of the cofucion matrix: true negative, false positive, false negative, true positive.\n",
    "    sensitivity,specificity=sentivity_specificity(y_true, y_pred)\n",
    "    return acc, roc_auc, importance,sensitivity,specificity\n",
    "\n",
    "\n",
    "def LOOCV(X,y,model,scaler,imputer):\n",
    "    #define the split mechanism as leave one out for evaluation \n",
    "    cv = LeaveOneOut()\n",
    "    model=model\n",
    "    #Create three lists to store the true y values (real and predicted) and the importance values for each iteration of leave one out validation\n",
    "    y_true, y_pred = list(), list()\n",
    "    #Run the leave one out \n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # split data, using just one sample as the test \n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        #Scale the data if called in the definition, where \"None\" means no scaling is applied\n",
    "        X_train,X_test=scale_data(scaler,X_train,X_test)\n",
    "        #Impute missing values using the technique indicated where \"knn\" is k-nearest neighbor and \"mean\" is the mean.\n",
    "        X_train,X_test=impute_data(imputer,X_train,X_test)\n",
    "        #Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        #Evaluate the model\n",
    "        yhat = model.predict(X_test)\n",
    "        #Store the predicted and true values of \"y\"\n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(yhat[0])\n",
    "        \n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    fpr,tpr,threshold=roc_curve(y_true,y_pred,pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #Compute the four components of the cofucion matrix: true negative, false positive, false negative, true positive.\n",
    "    sensitivity,specificity=sentivity_specificity(y_true, y_pred)\n",
    "    return acc, roc_auc,sensitivity,specificity\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
